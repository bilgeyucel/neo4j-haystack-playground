{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prosto/neo4j-haystack-playground/blob/main/neo4j_haystack_journey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/54b1f372f6f44e6851a5fa8bc1a1f554aa1dd080/images/neo4-haystack-friendship.svg)\n",
        "\n"
      ],
      "metadata": {
        "id": "dNm-nX0d5yrP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "# Agenda\n",
        "\n",
        "*   **Introduction** üëãüèº\n",
        "*   **Meet Neo4j** üï∏\n",
        "*   **Meet Haystack 2.0** üß©\n",
        "*   **Neo4j Document Store** üèóÔ∏è\n",
        "*   **Explore RAG Pipelines** üîç\n",
        "*   **Q/A** ‚ùì"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "qkBOHgLe9iSO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "\n",
        "### First steps towards Graph + RAG + Haystack\n",
        "\n",
        "Idea to build Neo4j + Haystack integration came after investigation about representing legislation using Graphs with complex relationships between legal **documents**. In the context of semantic search of legal docs Graphs seemed like a natural choice as a way to effectively ground LLMs in RAG pipelines. At the time there were news about Neo4j introducing support for vector indexes. Haystack with its component based NLP framework appeared well structured and documented. I liked the idea of pipelines with components having well defined interfaces (e.g. input/output slots, document stores). I decided to build the integration and learn both technolgies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thinking Graphs\n",
        "\n",
        "Modeling legislation, for example, is a complex task and simple chunking strategies which existed at the time did not seem to fulfill requirements. One needs to effectively decompose legislation into meaningful pieces which are inter-connected, easily queriable as \"traceable data sources\". Having both Graph nodes and vector indexes in the same database helps to reduce amount of queries and simplify RAG solutions.\n",
        "\n",
        "Below are some examples of Graps related to legislation to give you an idea of how to structure such content:\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr><th>Legsilators (Congress)</th><th>Clauses</th></tr>\n",
        "<tr>\n",
        "<td bgcolor=\"5b6663\">\n",
        "  <img src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/54b1f372f6f44e6851a5fa8bc1a1f554aa1dd080/images/legis-graph.svg\"/></td>\n",
        "<td bgcolor=\"5b6663\">\n",
        "  <img src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/54b1f372f6f44e6851a5fa8bc1a1f554aa1dd080/images/legis-clauses.svg\"/>\n",
        "</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td>Source: <a href=\"https://github.com/jbarrasa/goingmeta/tree/main/session23\">Going Meta</a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Apart from retrieving context for LLM prompts using semantic search your RAG peipeline could additionally perform more complex queries to tune the information being retrieved. E.g. only search for documents issued by a particular body (Committee) for a given law domain.\n",
        "\n",
        "Neo4j gives many benefits if we compare it to \"single-purpose\" vector databases:\n",
        "\n",
        "- Role-based security\n",
        "- Advanced queries using [Cypher](https://neo4j.com/docs/cypher-manual/current/introduction/cypher_overview/)\n",
        "- Both Full-Text and Semantic search indexes\n",
        "- [Schema Constraints](https://neo4j.com/docs/cypher-manual/current/constraints/)\n",
        "- ACID transactions, cluster support, runtime failover"
      ],
      "metadata": {
        "id": "HAoOYkD39r4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Haystack Pipelines are also Graphs üßê\n",
        "\n",
        "\n",
        "> To build modern search pipelines with LLMs, you need two things: powerful components and an easy way to put them together. The Haystack pipeline is built for this purpose and enables you to design and scale your interactions with LLMs.\n",
        "\n",
        "> The pipelines in Haystack 2.0 are directed **multigraphs** of different Haystack components and integrations. They give you the freedom to connect these components in various ways. This means that the pipeline doesn't need to be a continuous stream of information. With the flexibility of Haystack Pipelines, you can have simultaneous flows, standalone components, loops, and other types of connections.\n",
        "\n",
        "Learn more from the [Pipelines](https://docs.haystack.deepset.ai/docs/pipelines) documentatiion.\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr><th>Sample Pipeline</th></tr>\n",
        "<tr>\n",
        "<td align=\"center\" bgcolor=\"202424\">\n",
        "  <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/generic-pipeline-sample.png?raw=true\"/>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "a8-S2C4499fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meet Neo4j\n",
        "\n",
        "> Neo4j uses a¬†property graph¬†database model. A graph data structure consists of¬†nodes¬†(discrete objects) that can be connected by¬†relationships. Below is the image of a graph with three nodes (the circles) and three relationships (the arrows).\n",
        "\n",
        "> Neo4j is a native graph database, which means that it implements a true graph model all the way down to the storage level. The data is stored as you whiteboard it, instead of as a \"graph abstraction\" on top of another technology."
      ],
      "metadata": {
        "id": "1QF_e2pp9aXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The property graph model\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "<td align=\"center\" bgcolor=\"202424\">\n",
        "  <img src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/54b1f372f6f44e6851a5fa8bc1a1f554aa1dd080/images/the-property-graph-model.svg\" />\n",
        "</td>\n",
        "</tr>\n",
        "<table>\n",
        "\n",
        "Nodes¬†are the entities in the graph.\n",
        "\n",
        "1. Nodes can be tagged with¬†labels, representing their different roles in your domain (for example,¬†Person).\n",
        "2. Nodes can hold any number of key-value pairs, or¬†properties¬†(for example,¬†name).\n",
        "3. Node labels may also attach metadata (such as index or constraint information) to certain nodes.\n",
        "\n",
        "Relationships¬†provide directed, named connections between two node entities (for example,¬†Person¬†`LOVES`¬†Person).\n",
        "\n",
        "1. Relationships always have a direction, a type, a start node, and an end node, and they can have properties, just like nodes.\n",
        "2. Nodes can have any number or type of relationships without sacrificing performance.\n",
        "3. Although relationships are always¬†directed, they can be navigated efficiently in any direction.\n",
        "\n",
        "Below is another example of a Movies Graph:\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "<td align=\"center\" bgcolor=\"202424\">\n",
        "  <img src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/54b1f372f6f44e6851a5fa8bc1a1f554aa1dd080/images/movies-graph-model.svg\" />\n",
        "</td>\n",
        "</tr>\n",
        "<table>\n"
      ],
      "metadata": {
        "id": "Yb5r1XREO7Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation Options\n",
        "\n",
        "1. [Neo4j AuraDB](https://neo4j.com/cloud/platform/aura-graph-database/)¬†is a fully managed cloud service and a good place to start for anyone interested in graph technologies. Besides the free option, you can select the subscription plan that suits you best.\n",
        "2. [Neo4j Database](https://neo4j.com/deployment-center/)¬†can be installed on-premises and deployed in various systems\n",
        "3. The Neo4j Docker image¬†provides a standard package of Neo4j Community Edition and Enterprise Edition for a variety of versions.\n",
        "4. [Neo4j Desktop](https://neo4j.com/docs/desktop-manual/current/)¬†is one of the ways to set up an environment for developing an application with Neo4j and Cypher¬Æ. Download Neo4j Desktop from¬†https://neo4j.com/download/¬†and follow the installation instructions for your operating system. Neo4j Desktop comes with a variety of tools that can be installed as plugins.\n",
        "5. [Neo4j Sandbox](https://neo4j.com/sandbox/)¬†provides a number of example datasets that can help you to learn more about Neo4j graph database and Cypher queries applied to a specific use case.\n",
        "\n",
        "The simplest way to start database locally would be with Docker container:\n",
        "\n",
        "```bash\n",
        "docker run \\\n",
        "    --restart always \\\n",
        "    --publish=7474:7474 --publish=7687:7687 \\\n",
        "    --env NEO4J_AUTH=neo4j/passw0rd \\\n",
        "    neo4j:5.15.0\n",
        "```\n",
        "\n",
        "> **Note** Assuming you have a docker container running navigate to http://localhost:7474 to open [Neo4j Browser](https://neo4j.com/docs/browser-manual/current/) to explore graph data and run Cypher queries."
      ],
      "metadata": {
        "id": "YXL7ATNqYRW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cypher with Movies\n",
        "\n",
        "Lets prepare a Movies Graph database according to the property graph model example given above. We will use it to explore Vector Index setup.\n",
        "\n",
        "If working in Google Colab easiest option is to quickly start a free cloud instance in [AuraDB](https://neo4j.com/cloud/platform/aura-graph-database/). Once the instance is up and running and assuming you have stored the credentials you could navigate to the [Neo4j Broswer App](https://browser.neo4j.io/) and connect to the instance.\n",
        "\n",
        "Run the following query `:play movie-graph` and you should be able to see the \"Movie Graph Guide\" running as a result. As part of that guide there will be a \"single Cypher query statement composed of multiple `CREATE` clauses. This will create the movie graph..\". The guide should also help you to learn basic Cypher query syntax.\n",
        "\n",
        "Below is an example `CREATE` clause to add a Movie and Actors with `:ACTED_IN` relationships:\n",
        "\n",
        "```cypher\n",
        "CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})\n",
        "\n",
        "CREATE (Keanu:Person:Actor {name:'Keanu Reeves', born:1964})\n",
        "CREATE (Laurence:Person:Actor {name:'Laurence Fishburne', born:1961})\n",
        "\n",
        "CREATE\n",
        "  (Keanu)-[:ACTED_IN {roles:['Neo']}]->(TheMatrix),\n",
        "  (Laurence)-[:ACTED_IN {roles:['Morpheus']}]->(TheMatrix)\n",
        "```"
      ],
      "metadata": {
        "id": "80e-xRhbfBX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run queries with Neo4j Python Driver"
      ],
      "metadata": {
        "id": "ojowpnVoi1oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "[The Official Neo4j Driver for Python](https://neo4j.com/docs/api/python-driver/current/api.html) can be installed as follows:"
      ],
      "metadata": {
        "id": "o-iy0siAm_cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "xFU5zJZyivsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create helper function to query Neo4j using Cypher:\n",
        "<a name=\"cell_cypher_read_query\"/>"
      ],
      "metadata": {
        "id": "cZpMxv5Tm-HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase, RoutingControl\n",
        "from google.colab import userdata\n",
        "\n",
        "GRAPH_DB_URI = userdata.get(\"GRAPH_DB_URI\")\n",
        "GRAPH_DB_NAME = userdata.get(\"GRAPH_DB_NAME\")\n",
        "GRAPH_DB_AUTH = (\"neo4j\", userdata.get(\"GRAPH_DB_SECRET\"))\n",
        "\n",
        "def cypher_read_query(query, **parameters):\n",
        "  with GraphDatabase.driver(GRAPH_DB_URI, auth=GRAPH_DB_AUTH) as driver:\n",
        "    records, _, _ = driver.execute_query(query,\n",
        "                                         parameters_=parameters,\n",
        "                                         database_=GRAPH_DB_NAME,\n",
        "                                         routing_=RoutingControl.READ)\n",
        "    return records\n",
        "\n",
        "def cypher_write_query(query, **parameters):\n",
        "  with GraphDatabase.driver(GRAPH_DB_URI, auth=GRAPH_DB_AUTH) as driver:\n",
        "    result = driver.execute_query(query,\n",
        "                                  parameters_=parameters,\n",
        "                                  database_=GRAPH_DB_NAME,\n",
        "                                  routing_=RoutingControl.WRITE)\n",
        "    return result"
      ],
      "metadata": {
        "id": "psNsyMAKjdut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example (1): Find the actor named \"Tom Hanks\""
      ],
      "metadata": {
        "id": "LNmCp5lOn00q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = cypher_read_query(\"MATCH (tom {name: $name}) RETURN tom\", name=\"Tom Hanks\")\n",
        "[record.data().get(\"tom\") for record in records]"
      ],
      "metadata": {
        "id": "bR0hYTtjn6JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example (2): Find movies released in the 1990s"
      ],
      "metadata": {
        "id": "1db-0DVvpKR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = cypher_read_query(\n",
        "    \"MATCH (nineties:Movie) WHERE nineties.released >= 1990 AND nineties.released < 2000 RETURN nineties.title\",\n",
        "    year_start=1990, year_end=2000\n",
        ")\n",
        "[record.data() for record in records]"
      ],
      "metadata": {
        "id": "SrHki_wKpPTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example (3): List all Tom Hanks Movies"
      ],
      "metadata": {
        "id": "wMOXW9_Eqg5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "records = cypher_read_query(\n",
        "    \"MATCH (tom:Person {name: $name})-[:ACTED_IN]->(tomHanksMovies) RETURN tom,tomHanksMovies\",\n",
        "    name=\"Tom Hanks\"\n",
        ")\n",
        "[record.data().get(\"tomHanksMovies\") for record in records]"
      ],
      "metadata": {
        "id": "TU22Qymeqv6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector search indexes\n",
        "\n",
        "> Node vector [search indexes](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/) were released as a public beta in Neo4j 5.11 and general availability in Neo4j 5.13.\n",
        "\n",
        "<table>\n",
        "<tr><td>\n",
        "<img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/grounding-llm-neo4j-vector-index.png?raw=true\"/>\n",
        "</td></tr>\n",
        "<tr><td>\n",
        "Source: <a href=\"https://neo4j.com/labs/genai-ecosystem/vector-search/\">Neo4j Vector Index and Search</a>\n",
        "</td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "NuhSZo31xkoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and configure vector indexes\n",
        "\n",
        "You can create vector indexes using the `CREATE VECTOR INDEX` command. An index can be given a unique name when created (or get a generated one), which is used to reference the specific index when querying or dropping it."
      ],
      "metadata": {
        "id": "Evwgv9Ea8Ahb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_index_query = \"\"\"\n",
        "  CREATE VECTOR INDEX `movie-embeddings` IF NOT EXISTS\n",
        "  FOR (n:Movie) ON (n.embedding)\n",
        "  OPTIONS {indexConfig: {\n",
        "  `vector.dimensions`: $dimensions,\n",
        "  `vector.similarity_function`: $similarity_function\n",
        "  }}\n",
        "\"\"\"\n",
        "\n",
        "cypher_write_query(create_index_query, dimensions=384, similarity_function=\"cosine\")"
      ],
      "metadata": {
        "id": "KCvGkur48QJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query index information:"
      ],
      "metadata": {
        "id": "CMdTTs79MhMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_read_query(\"SHOW VECTOR INDEXES YIELD name, type, entityType, labelsOrTypes, properties, options\")"
      ],
      "metadata": {
        "id": "ZNMh-o3UMQg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create embeddings with sentence_transformers"
      ],
      "metadata": {
        "id": "VFz7KPKd-30X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "KyB223RH--7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "movie_nodes =  [record.get(\"movie\") for record in cypher_read_query(\"MATCH (movie:Movie) RETURN movie\")]\n",
        "\n",
        "tagline_embeddings = model.encode([node.get(\"tagline\") for node in movie_nodes])\n",
        "movie_embeddings = [{\"id\": node.element_id, \"vector\": embedding} for embedding, node in zip(tagline_embeddings, movie_nodes)]\n",
        "\n",
        "cypher_write_query(\"\"\"\n",
        "  WITH $movie_embeddings AS batch\n",
        "  UNWIND batch as movie_embedding\n",
        "  MATCH (n:Movie) WHERE elementId(n) = movie_embedding.id\n",
        "  CALL db.create.setNodeVectorProperty(n, 'embedding', movie_embedding.vector)\n",
        "  \"\"\", movie_embeddings=movie_embeddings)"
      ],
      "metadata": {
        "id": "8uxE8ZW7_pk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_read_query(\"SHOW VECTOR INDEXES YIELD name, type, entityType, labelsOrTypes, properties, options\")"
      ],
      "metadata": {
        "id": "hcBK7pRd9uWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query a vector index\n",
        "\n",
        "You can query a vector index using the `db.index.vector.queryNodes` procedure."
      ],
      "metadata": {
        "id": "tYRM7HqT-Jmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_query = \"crack the cypher\" # @param {type:\"string\"}\n",
        "query_mbedding = SentenceTransformer(\"all-MiniLM-L6-v2\").encode(text_query)\n",
        "\n",
        "cypher_read_query(\"\"\"\n",
        "  CALL db.index.vector.queryNodes('movie-embeddings', $top_k, $embedding)\n",
        "  YIELD node AS similarMovie, score\n",
        "\n",
        "  MATCH (similarMovie) WHERE similarMovie.released > 2000\n",
        "  RETURN similarMovie.tagline AS tagline, score\n",
        "\"\"\", embedding=query_mbedding, top_k=3)"
      ],
      "metadata": {
        "id": "kEsYcPll-VJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meet Haystack 2.0\n",
        "\n"
      ],
      "metadata": {
        "id": "-BGY6JjdhOu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Haystack is an open-source framework for building production-ready LLM applications, retrieval-augmented generative pipelines and state-of-the-art search systems that work intelligently over large document collections.**\n",
        "\n",
        "Please explore the [fabulous documentation](https://docs.haystack.deepset.ai/docs/intro) for more details.\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr><th>Haystack Ecosystem</th></tr>\n",
        "<tr>\n",
        "<td align=\"center\" bgcolor=\"202424\">\n",
        "  <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/haystack-universe.png?raw=true\"/>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "and more..."
      ],
      "metadata": {
        "id": "uGY8zFtW_nkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Components\n",
        "\n",
        "Components are the building blocks of a pipeline. They perform tasks such as preprocessing, retrieving, or summarizing text while routing queries through different branches of a pipeline.\n",
        "\n",
        "Below are some examples of components which we will be using in pipelines later in the notebook.\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "  <td align=\"center\" bgcolor=\"202424\">\n",
        "    <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/retriever-class-diagram.png?raw=true\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "<br/>\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "  <td bgcolor=\"202424\">\n",
        "    <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/generator-class-diagram.png?raw=true\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Please notice the following:\n",
        "\n",
        "* Each Haystack component is usually created with a set of initialization parameters (e.g. see `model`, `url` in `HuggingFaceTGIGenerator` or `top_k` in `InMemoryEmbeddingRetriever`)\n",
        "* Component can be directly invoked in python code by calling its `run` method\n",
        "* The component usually expects inputs which you would provide to the `run` method\n",
        "* The result of component execution is a python dictionary and is outlined by `OutputType` note in the diagram.\n",
        "\n",
        "For better understanding of how components work please refer to the [documentation](https://docs.haystack.deepset.ai/docs/components)."
      ],
      "metadata": {
        "id": "XO_tn7oRJMKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Classes\n",
        "\n",
        "> In Haystack, there are a handful of core classes that are regularly used in many different places. These are classes that carry data through the system and you are likely to interact with these as either the input or output of your pipeline.\n",
        "\n",
        "> Haystack 2.0 uses data classes to help components communicate with each other in a simple and modular way. By doing this, data flows seamlessly through the Haystack Pipelines.\n",
        "\n",
        "Leearn more about data classes in [Haystack docs](https://docs.haystack.deepset.ai/docs/data-classes).\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "  <td bgcolor=\"202424\" align=\"center\">\n",
        "  <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/document-class-diagram.png?raw=true\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "> Document represents a central data abstraction in Haystack, capable of holding text, tables, and binary data.\n",
        "\n",
        "In our case we are interested in the `Document` a lot as it is going to be the main data structure which will be used to interact with Neo4j. The `Document` is going to be stored in Neo4j as a node, and both `meta` and `embedding` attributes will be used to represent additional data points if needed."
      ],
      "metadata": {
        "id": "JvmcyvcJf3r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Document Store\n",
        "\n",
        "> [Document Store](https://docs.haystack.deepset.ai/docs/document-store) is an object that stores your Documents. In Haystack, a Document Store is different from a component, as it doesn‚Äôt have the `run()` method. You can think of it as an interface to your database ‚Äì you put the information there, or you can look through it. This means that a Document Store is not a piece of a Pipeline, but rather a tool that the components of a pipeline have access to and can interact with.\n",
        "\n",
        "> The most common way to use a Document Store in Haystack is to fetch documents using a Retriever. A Document Store will often have a corresponding Retriever to get the most out of specific technologies.\n",
        "\n",
        "Below you can see methods of the [DocumentStore Protocol](https://docs.haystack.deepset.ai/docs/document-store#documentstore-protocol):\n",
        "\n",
        "<table width=\"100%\">\n",
        "<tr>\n",
        "  <td bgcolor=\"202424\" align=\"center\">\n",
        "  <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/document-store-class-diagram.png?raw=true\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "DocumentStore Protocol has to be implemented if you are creating a [custom Document Store](https://docs.haystack.deepset.ai/docs/creating-custom-document-stores). The `neo4j-haystack` packge implements all methods from the protocol in the [Neo4jDocumentStore](https://prosto.github.io/neo4j-haystack/reference/neo4j_store/) class."
      ],
      "metadata": {
        "id": "YeUlNt6TiCo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Pipelines with InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "TUYzpddLmf12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oour goal here is to quickly demonstrate how pipelines work and see how Doocument Stores are being used in particular. Later we will replace `InMemoryDocumentStore` with `Neo4jDocumentStore` and pipelines will practically remain same."
      ],
      "metadata": {
        "id": "P0JImWMP9TxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Game Of Thrones (Data)"
      ],
      "metadata": {
        "id": "KKxzqQ6bmvRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOT_DOCS_DIR=\"data/got\"\n",
        "GOT_ZIP_URL=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt6.zip\""
      ],
      "metadata": {
        "id": "uxICr2pH8k8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download Game of Thrones (GOT) wiki\n",
        "!mkdir -p $GOT_DOCS_DIR\n",
        "!wget $GOT_ZIP_URL -O wiki_gameofthrones_txt6.zip\n",
        "!unzip -o wiki_gameofthrones_txt6.zip -d $GOT_DOCS_DIR"
      ],
      "metadata": {
        "id": "2HSMdUvlnktL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Haystack"
      ],
      "metadata": {
        "id": "qdZjQ0HhuHpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install haystack-ai"
      ],
      "metadata": {
        "id": "N1H7r_ihuMql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The [InMemoryDocumentStore](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore) is a very simple document store with no extra services or dependencies.\n",
        "\n",
        "> It is great for experimenting with Haystack, however we do not recommend using it for production."
      ],
      "metadata": {
        "id": "YMhHvHhL99YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore()"
      ],
      "metadata": {
        "id": "9Ho9fwHXxxFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indexing Pipeline with InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "06n7KlcZmsqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.converters import TextFileToDocument\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.writers import DocumentWriter\n",
        "\n",
        "pipe = Pipeline()\n",
        "pipe.add_component(\"text_file_converter\", TextFileToDocument())\n",
        "pipe.add_component(\"cleaner\", DocumentCleaner())\n",
        "pipe.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=250, split_overlap=30))\n",
        "pipe.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
        "pipe.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
        "\n",
        "pipe.connect(\"text_file_converter.documents\", \"cleaner.documents\")\n",
        "pipe.connect(\"cleaner.documents\", \"splitter.documents\")\n",
        "pipe.connect(\"splitter.documents\", \"embedder.documents\")\n",
        "pipe.connect(\"embedder.documents\", \"writer.documents\")\n",
        "\n",
        "# Take the docs data directory as input and run the pipeline\n",
        "file_paths = [GOT_DOCS_DIR / Path(name) for name in os.listdir(GOT_DOCS_DIR)]\n",
        "result = pipe.run({\"text_file_converter\": {\"sources\": file_paths}})\n"
      ],
      "metadata": {
        "id": "ZzJXqNyKmq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RAG Pipeline with InMemoryDocumentStore"
      ],
      "metadata": {
        "id": "u5OyW5U_wOpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from haystack import GeneratedAnswer, Pipeline\n",
        "from haystack.components.builders.answer_builder import AnswerBuilder\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "from haystack.utils import Secret\n",
        "\n",
        "HF_TOKEN = Secret.from_token(userdata.get(\"HF_TOKEN\"))\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Given these documents, answer the question.\\nDocuments:\n",
        "{% for doc in documents %}\n",
        "    {{ doc.content }}\n",
        "{% endfor %}\n",
        "\n",
        "\\nQuestion: {{question}}\n",
        "\\nAnswer:\n",
        "\"\"\"\n",
        "rag_pipeline = Pipeline()\n",
        "rag_pipeline.add_component(\n",
        "    \"query_embedder\",\n",
        "    SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\", progress_bar=False),\n",
        ")\n",
        "rag_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\n",
        "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
        "rag_pipeline.add_component(\n",
        "    \"llm\",\n",
        "    HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-v0.1\", token=HF_TOKEN),\n",
        ")\n",
        "rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
        "\n",
        "rag_pipeline.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
        "rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
        "rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
        "rag_pipeline.connect(\"llm.meta\", \"answer_builder.meta\")\n",
        "rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")\n",
        "\n",
        "# Ask a question on the data you just added.\n",
        "question = \"Who created the Dothraki vocabulary?\"\n",
        "result = rag_pipeline.run(\n",
        "    {\n",
        "        \"query_embedder\": {\"text\": question},\n",
        "        \"retriever\": {\"top_k\": 3},\n",
        "        \"prompt_builder\": {\"question\": question},\n",
        "        \"answer_builder\": {\"query\": question},\n",
        "    }\n",
        ")\n",
        "\n",
        "answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n"
      ],
      "metadata": {
        "id": "LEgIzWv5wclV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(answer)"
      ],
      "metadata": {
        "id": "mOxHuqQBzemW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neo4j Document Store"
      ],
      "metadata": {
        "id": "xreIeqwm8cGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we already covered main components and concepts of both Neo4j and Haystack we should be ready to discuss the `neo4j-haystack` package and what it offers. In particular we will start with some implementation details and show how `Neo4jDcumentStore` can be used to both create and query documents in Neo4j."
      ],
      "metadata": {
        "id": "EZ1_tuvGx9U1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Big Picture"
      ],
      "metadata": {
        "id": "hZ12G7k-yWu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table width=\"100%\">\n",
        "<tr>\n",
        "  <td bgcolor=\"202424\" align=\"center\">\n",
        "  <img src=\"https://github.com/prosto/neo4j-haystack-playground/blob/main/images/big-picture.png?raw=true\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "The conceptual diagram above demonstrats keys areas involved in using `neo4j-haystack` library and its components:\n",
        "\n",
        "1. You would usually be building Haaystack pipelines with Neo4j related components in it. Please notice the `retriever` component in the pipeline which ships with the package\n",
        "2. `neo4j-haystack` library comes with a number of components:\n",
        "\n",
        "  - [Neo4jDocumentStore](https://prosto.github.io/neo4j-haystack/reference/neo4j_store/) -  Document store for Neo4j Database with support for dense retrievals using Vector Search Index, implements the required [Protocol](https://docs.haystack.deepset.ai/v2.0/docs/document-store#documentstore-protocol). Document properties are stored as graph nodes. Embeddings are stored as part of node properties along with the rest of attributes (including meta). `Neo4jDocumentStore` also provides additional methods to query embeddings and manage VectorIndex.\n",
        "  - [Neo4jEmbeddingRetriever](https://prosto.github.io/neo4j-haystack/reference/neo4j_retriever/#neo4j_haystack.components.neo4j_retriever.Neo4jEmbeddingRetriever) - is a typical [retriever component](https://docs.haystack.deepset.ai/v2.0/docs/retrievers) which can be used to query vector store index and find related Documents. The component uses `Neo4jDocumentStore` to query embeddings.\n",
        "  - [Neo4jDynamicDocumentRetriever](https://prosto.github.io/neo4j-haystack/reference/neo4j_retriever/#neo4j_haystack.components.neo4j_retriever.Neo4jDynamicDocumentRetriever) is also a retriever component in a sense that it can be used to query Documents in Neo4j. However it is decoupled from `Neo4jDocumentStore` and allows to run arbitrary [Cypher query](https://neo4j.com/docs/cypher-manual/current/queries/) to extract documents. Practically it is possible to query Neo4j same way `Neo4jDocumentStore` does, including vector search.\n",
        "\n",
        "3. The `neo4j-haystack` library uses [Python Driver](https://neo4j.com/docs/api/python-driver/current/api.html#api-documentation) and\n",
        "[Cypher Queries](https://neo4j.com/docs/cypher-manual/current/introduction/) to interact with Neo4j database and hide all complexities under the hood. In particular [Neo4jClient](https://prosto.github.io/neo4j-haystack/reference/neo4j_client/) ia acting as a data access layer and is handling all interactions with database by invoking Cypher queries.\n",
        "4. In Neo4j [Vector search index](https://neo4j.com/docs/cypher-manual/current/indexes-for-vector-search/) is being used for storing document embeddings and dense retrievals.\n",
        "\n",
        "> As of Neo4j 5.13, the vector search index is no longer a beta feature, consider using a version of the database \">= 5.13\". You could explore Known issues and Limitations in the [documentation](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/).\n",
        "\n"
      ],
      "metadata": {
        "id": "AQpeZYholVZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Package Structure\n",
        "\n",
        "The source code of the package is available at https://github.com/prosto/neo4j-haystack. See below the overall structure with main parts highlighted with comments"
      ],
      "metadata": {
        "id": "V5Pj11nP5FHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ CHANGELOG.md\n",
        "‚îú‚îÄ‚îÄ CONTRIBUTING.md # How to install the project locally and contribute\n",
        "‚îú‚îÄ‚îÄ LICENSE.txt\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ mkdocs.yml\n",
        "‚îú‚îÄ‚îÄ pyproject.toml\n",
        "‚îú‚îÄ‚îÄ data\n",
        "‚îú‚îÄ‚îÄ docs # mkdocs pages for the API documentation web site\n",
        "‚îú‚îÄ‚îÄ examples\n",
        "‚îú‚îÄ‚îÄ scripts # Helper scripts, e.g. load sample data from hf datasets\n",
        "‚îú‚îÄ‚îÄ site\n",
        "‚îú‚îÄ‚îÄ src\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ neo4j_haystack\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ __about__.py\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ client\n",
        "‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ neo4j_client.py # Neo4j data access with Neo4jClient, Cypher queries are not exposed to the Neo4jDocumentStore\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ components\n",
        "‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ neo4j_retriever.py # retrievers (e.g. Neo4jEmbeddingRetriever)\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ document_stores\n",
        "‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ neo4j_store.py # Implementation of the Neo4jDocumentStore, uses Neo4jClient to interact with Neo4j\n",
        "‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ utils.py\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ errors.py\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ metadata_filter # Utilities to parse metadata filters\n",
        "‚îÇ           ‚îú‚îÄ‚îÄ neo4j_query_converter.py\n",
        "‚îÇ           ‚îî‚îÄ‚îÄ parser.py\n",
        "‚îî‚îÄ‚îÄ tests # Unit/Integration tests for better confidence when releasing :)\n",
        "```"
      ],
      "metadata": {
        "id": "gO88xEea7leM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Neo4jDocumentStore"
      ],
      "metadata": {
        "id": "AxahRQ714Lj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install `neo4-haystack` package"
      ],
      "metadata": {
        "id": "RCpsukSa39_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers # required for producing embeddings in our examples\n",
        "!pip install neo4j-haystack"
      ],
      "metadata": {
        "id": "VLVGEGrz4ENQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create DocumentStore with settings"
      ],
      "metadata": {
        "id": "DkFQjvEV9Tgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We are [cleaning up](https://neo4j.com/docs/aura/auradb/managing-databases/database-actions/#_resetting_an_instance) existing Free instance in AuraDB before proceeding to the next step. There is \"Reset\" option in the console which wipes out all data. The following warning will be displayed before reset happens:*\n",
        "\n",
        "> *Resetting into a blank state will erase all data, so please be certain. If you want to keep the current data please take a snapshot and export it.*"
      ],
      "metadata": {
        "id": "Zz8njbP-Ekrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from neo4j_haystack import Neo4jDocumentStore\n",
        "\n",
        "GRAPH_DB_URI = userdata.get(\"GRAPH_DB_URI\")\n",
        "GRAPH_DB_NAME = userdata.get(\"GRAPH_DB_NAME\")\n",
        "GRAPH_DB_SECRET = userdata.get(\"GRAPH_DB_SECRET\")\n",
        "\n",
        "document_store = Neo4jDocumentStore(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        "    index=\"document-embeddings\", # The name of the Vector Index in Neo4j\n",
        "    node_label=\"Document\", # Providing a label to Neo4j nodes which store Documents\n",
        "    embedding_dim=384, # default is 768\n",
        "    embedding_field=\"embedding\",\n",
        "    similarity=\"cosine\", # \"cosine\" is default value for similarity\n",
        "    progress_bar=False,\n",
        "    create_index_if_missing=False,\n",
        "    recreate_index=False,\n",
        "    write_batch_size=100,\n",
        "    verify_connectivity=True # Will try connect to Neo4j instance with given credentials as soon as Neo4jDocumentStore is created\n",
        ")"
      ],
      "metadata": {
        "id": "9bZDmJtG9XSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* With `verify_connectivity=True` if the code above runs without error it means connection to Neo4j was succesful\n",
        "* `node_label=\"Movie\"` will ensure we are pointing Document Store to the nodes in the Movie Graph\n",
        "* `create_index_if_missing=False` will make sure we are not creating index\n",
        "* `recreate_index` is usefull during locl testing if you would like to recreate index each time if `True`\n",
        "* `similarity` is `cosine` by default (you could skip the setting of the value). another supported options is `l2` which maps to `euclidean` in Neo4j\n",
        "* `embedding_dim` value depends on model you are using for embeddings, e.g. for \"all-MiniLM-L6-v2\" from sentence-transformers it is `384`\n",
        "* `embedding_field` specified naame of the node property which will be used to store and query embeddings, as well as vector indexing configuration.\n",
        "\n",
        "> Note: If you wondering why `username` is by default \"neo4j\" and is not a secret thats becuase \"neo4j\" user is created by default by AuraDB Free instance."
      ],
      "metadata": {
        "id": "-hdzqIyOGc7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you try to count number of documents in the graph you should get `0` at this point"
      ],
      "metadata": {
        "id": "D5YDZg0_Xa85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_store.count_documents()"
      ],
      "metadata": {
        "id": "NKElbfsXHUKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets crete the instance once more, We will omit some of the attributes and leave those with default values, but also instruct our code to create index if it does not exist"
      ],
      "metadata": {
        "id": "jf8pmDKiXkCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# same as above but `create_index_if_missing=True` meaning index will be created automatically\n",
        "document_store = Neo4jDocumentStore(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        "    embedding_dim=384,\n",
        "    create_index_if_missing=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bUh0ckfTYkMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its time to see if index has been created in Neo4j, lets verify by running the following Cypher query:"
      ],
      "metadata": {
        "id": "2-4cwpaRZDkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_read_query(\"SHOW VECTOR INDEXES YIELD name, type, entityType, labelsOrTypes, properties, options\")"
      ],
      "metadata": {
        "id": "pGj7E7dQZJzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result should be a record containing index information matching parameters speicified for the `Neo4jDocumentStore` instance."
      ],
      "metadata": {
        "id": "DcEs-vjLZRmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, Neo4j connection properties could be specified using a dedicated [Neo4jClientConfig](https://prosto.github.io/neo4j-haystack/reference/neo4j_client/#neo4j_haystack.client.neo4j_client.Neo4jClientConfig) data class. This additional data structure was created for code reuse and convenience so you could specify conneciton settings once and then share it betwwen differrent instances of `Neo4jDocumentStore`. Internally `Neo4jDocumentStore` will create `Neo4jClientConfig` to hold credentials even if you directly provide credentials to the DocumentStore constructor as in examples bove."
      ],
      "metadata": {
        "id": "jWsRYA0lZqPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j_haystack import Neo4jClientConfig, Neo4jDocumentStore\n",
        "\n",
        "client_config = Neo4jClientConfig(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        ")\n",
        "\n",
        "document_store = Neo4jDocumentStore(client_config=client_config, embedding_dim=384)"
      ],
      "metadata": {
        "id": "2GwpirdPbEbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Write data to Document Store\n",
        "\n"
      ],
      "metadata": {
        "id": "tfTuqFyQcs2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Neo4jDocumentStore`, according to Protocol, provides `write_documents` method which can be used to write data to Neo4j and also update embeddings on the documents if provided.\n",
        "\n",
        "Before we need to prepare some data in the [Document](https://docs.haystack.deepset.ai/docs/data-classes#document) format.\n",
        "\n",
        "The `movies.json` was prepared to easily map to Haystack Document model, see below an example of a single json movie entry:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id\": \"451999\",\n",
        "  \"content\": \"A 1916 film directed by Chester M. Franklin.\",\n",
        "  \"meta\": {\n",
        "    \"title\": \"Martha's Vindication\",\n",
        "    \"runtime\": 50.0,\n",
        "    \"vote_average\": 0.0,\n",
        "    \"release_date\": \"1916-02-20\",\n",
        "    \"genres\": [\"Drama\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "> **Important** `id` is provided in the json, each Document should haave an id field. If not provided the `Document` class will automatically create/generte it based on its contents.\n"
      ],
      "metadata": {
        "id": "hIIO5ZAM0IX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List\n",
        "\n",
        "from haystack import Document\n",
        "from urllib.request import urlopen\n",
        "\n",
        "MOVIES_DATA_URL=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/main/data/movies.json\"\n",
        "\n",
        "def movie_documents() -> List[Document]:\n",
        "    with urlopen(MOVIES_DATA_URL) as movies_json:\n",
        "        file_contents = movies_json.read()\n",
        "        docs_json = json.loads(file_contents)\n",
        "        return [Document.from_dict(doc_json) for doc_json in docs_json]\n",
        "\n",
        "documents=movie_documents()\n",
        "\n",
        "display(documents[0])"
      ],
      "metadata": {
        "id": "LyAd9JI6fdBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets write movie Documents to the store:"
      ],
      "metadata": {
        "id": "ji2JbQqWlOqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_store.write_documents(documents)"
      ],
      "metadata": {
        "id": "9KIV0-pkhQQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you curious how to obtain data recently written to Neo4j, lets query it with Cypher:\n",
        "> **Quick Action** Navigate to [cypher_read_query](#cell_cypher_read_query) definition"
      ],
      "metadata": {
        "id": "T4Cwxsralv9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_read_query(\"MATCH (doc:Document) RETURN doc LIMIT 5\")"
      ],
      "metadata": {
        "id": "vxUAIiysl4kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to Protocl methods, `Neo4jDocumentStore` provides a number of helper methods, `get_document_by_id` is one of those. See all public methods in the [API documentation](https://prosto.github.io/neo4j-haystack/reference/neo4j_store/)"
      ],
      "metadata": {
        "id": "Wo8kimSUmMx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_store.get_document_by_id(\"451999\").to_dict()"
      ],
      "metadata": {
        "id": "wT-yxMDemNXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Important** The above `to_dict` invocation creates pythoon `dict` from Document fields. You could call it with additional parameter `flatten=False` and in that case all metdata attributes (see original json from `movies.json`) will be stored under `meta` key (also as dictionary). In current implementation we expect `flatten=True` (default value) as Neo4j stores properties in a flat format (not nested)\n",
        "\n",
        "We will put Haystack Document representation and Neo4j graph node representation side by side for you to see how data is being stored and mapped:\n",
        "\n",
        "<table>\n",
        "<tr><th>Haystack</th><th>Neo4j (Node)</th></tr>\n",
        "<tr>\n",
        "<td>\n",
        "<pre>\n",
        "{\n",
        "  \"id\": \"451999\",\n",
        "  \"content\": \"A 1916 film directed by Chester M. Franklin.\",\n",
        "  \"dataframe\": null,\n",
        "  \"blob\": null,\n",
        "  \"score\": null,\n",
        "  \"embedding\": null,\n",
        "  \"title\": \"Martha's Vindication\",\n",
        "  \"vote_average\": 0.0,\n",
        "  \"genres\": [\"Drama\"],\n",
        "  \"release_date\": \"1916-02-20\",\n",
        "  \"runtime\": 50.0\n",
        "}\n",
        "<pre>\n",
        "</td>\n",
        "<td>\n",
        "<pre>\n",
        "{\n",
        "  \"identity\": 12,\n",
        "  \"labels\": [\"Document\"],\n",
        "  \"properties\": {\n",
        "    \"release_date\": \"1916-02-20\",\n",
        "    \"genres\": [\"Drama\"],\n",
        "    \"vote_average\": 0.0,\n",
        "    \"runtime\": 50.0,\n",
        "    \"id\": \"451999\",\n",
        "    \"title\": \"Martha's Vindication\",\n",
        "    \"content\": \"A 1916 film directed by Chester M. Franklin.\"\n",
        "  },\n",
        "  \"elementId\": \"4:bd65188c-5b0a-46c5-80ca-2ff365b9899a:12\"\n",
        "}\n",
        "</pre>\n",
        "</td>\n",
        "</tr>\n",
        "<table>\n",
        "\n",
        "> **Note:** Neo4j creates additional fields, e.g. `elementId` which are not controlled by DocumentStore. Hystack Document fields are mapped to Node's `properties`"
      ],
      "metadata": {
        "id": "9WEtYrZhm-xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We did not create embeddings (see `\"embedding\": null` above) before writing documents to Neo4j. We could leverage `sentence_transformers` to create embeddings as before. However there is another way. Haystack allows you to run components directly, not only inside pipeline, and `SentenceTransformersDocumentEmbedder` could help us with that.\n",
        "\n"
      ],
      "metadata": {
        "id": "GJ4610w-uFX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "document_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "document_embedder.warm_up() # will download the model during first run\n",
        "documents_with_embeddings = document_embedder.run(documents)"
      ],
      "metadata": {
        "id": "fGD_bJOLvSz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write documents with embeddings, in our case only embeddings are updated, rest of properties remain same:\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "document_store.write_documents(documents_with_embeddings.get(\"documents\"), DuplicatePolicy.OVERWRITE)"
      ],
      "metadata": {
        "id": "Mc-HW9KKvjTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve documents with embeddings:\n",
        "document_store.filter_documents()"
      ],
      "metadata": {
        "id": "WORy23Ahvt7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Neo4jDocumentStore` exposes `query_by_embedding` custom method to help you query Vector Index in Neo4j. We know there is a movie wwith the following description:\n",
        "\n",
        "> A film student robs a bank under the guise of shooting a short film about a bank robbery.\n",
        "\n",
        "We will embed a query which looks semantically sim ilar and ask document store to find the document for us.\n",
        "\n",
        "<a name=\"cell_embed_text\"></a>"
      ],
      "metadata": {
        "id": "XeejC-FswpP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "\n",
        "def embed_text(text):\n",
        "  text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  text_embedder.warm_up()\n",
        "\n",
        "  return text_embedder.run(text).get(\"embedding\")\n",
        "\n",
        "query_embedding = embed_text(\"A young fella pretending to be a good citizen but actually planning to commit a crime\")\n",
        "\n",
        "similar_documents = document_store.query_by_embedding(query_embedding, top_k=3)\n",
        "\n",
        "# expected document should be in the list (not necesarily first)\n",
        "display(similar_documents)"
      ],
      "metadata": {
        "id": "wYyMlXCXxsdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Metadata Filtering"
      ],
      "metadata": {
        "id": "LAgjEpHr6p5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You probably noticed `Neo4jDocumentStore` as part of its Document Store Protocol implementation provides `filter_documents` method. It has the following signature:\n",
        "\n",
        "```python\n",
        "filter_documents(self, filters: Optional[FilterType] = None) -> List[Document]\n",
        "```\n",
        "\n",
        "You can use it to retrieve documents from Neo4j with [metadata filters](https://docs.haystack.deepset.ai/v2.0/docs/metadata-filtering)\n",
        "\n",
        "Internally `Neo4jDocumentStore` converts filters into Cypher query, specifically into [WHERE clause](https://neo4j.com/docs/cypher-manual/current/clauses/where/). For that two utility classes [FilterParser](https://prosto.github.io/neo4j-haystack/reference/metadata_filter/parser/) and [Neo4jQueryConverter](https://prosto.github.io/neo4j-haystack/reference/metadata_filter/neo4j_query_converter/) parse and convert filters to Cypher syntaax respectively.\n",
        "\n",
        "The following example uses both classes to produce a parsed Cypher query:"
      ],
      "metadata": {
        "id": "9dgD-DHs6utd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j_haystack.metadata_filter import FilterParser, FilterType, Neo4jQueryConverter\n",
        "\n",
        "parser = FilterParser()\n",
        "converter = Neo4jQueryConverter(field_name_prefix=\"doc\")\n",
        "\n",
        "filters = {\n",
        "    \"operator\": \"OR\",\n",
        "    \"conditions\": [\n",
        "        {\n",
        "            \"operator\": \"AND\",\n",
        "            \"conditions\": [\n",
        "                {\"field\": \"type\", \"operator\": \"==\", \"value\": \"news\"},\n",
        "                {\"field\": \"likes\", \"operator\": \"!=\", \"value\": 100},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"operator\": \"AND\",\n",
        "            \"conditions\": [\n",
        "                {\"field\": \"type\", \"operator\": \"==\", \"value\": \"blog\"},\n",
        "                {\"field\": \"likes\", \"operator\": \">=\", \"value\": 500},\n",
        "            ],\n",
        "        },\n",
        "    ],\n",
        "}\n",
        "\n",
        "filter_ast = parser.parse(filters)\n",
        "cypher_query, params = converter.convert(filter_ast)\n",
        "\n",
        "cypher_query, params"
      ],
      "metadata": {
        "id": "yANBDOdO6tYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get the following query (applicable as `WHERE` clause):\n",
        "\n",
        "```cypher\n",
        "((doc.type = $fv_type AND doc.likes < $fv_likes) OR (doc.type = $fv_type_1 AND doc.likes >= $fv_likes_1))\n",
        "```\n",
        "\n",
        "with parameters (`params`):\n",
        "\n",
        "```python\n",
        "{\"fv_type\": \"news\", \"fv_likes\": 100, \"fv_type_1\": \"blog\", \"fv_likes_1\": 500}\n",
        "```\n",
        "\n",
        "> **Note** The reason Cypher query is accompanied with parameters is because we delegate data type conversion of parameter values to Neo4j Python Driver instead of repeating the logic in this class. See the full mapping of core and extended types in the Data Types document.\n"
      ],
      "metadata": {
        "id": "Bj5rbbl49d5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets find some movies, comedy is preferable üòÄ"
      ],
      "metadata": {
        "id": "Jo4DZVIhBwAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Comedy\" genre\n",
        "document_store.filter_documents({\n",
        "    \"field\": \"genres\",\n",
        "    \"operator\": \"in\",\n",
        "    \"value\": [\"Comedy\"]\n",
        "})\n"
      ],
      "metadata": {
        "id": "ySgAEjEGB_hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Comedy\" genre with averaging rating > 7\n",
        "document_store.filter_documents({\n",
        "    \"operator\": \"AND\",\n",
        "    \"conditions\": [\n",
        "        {\"field\": \"genres\", \"operator\": \"in\", \"value\": [\"Comedy\"]},\n",
        "        {\"field\": \"vote_average\", \"operator\": \">\", \"value\": 7},\n",
        "    ],\n",
        "})"
      ],
      "metadata": {
        "id": "r3PXPo1AEChZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`filter_documents` does not allow querying Neo4j graph embedding with metadata filters combined. `query_by_embedding` will give you that:\n",
        "\n",
        "> **Quick Action** Navigate to [embed_text](#cell_embed_text) definition"
      ],
      "metadata": {
        "id": "CAlJf3IGEQz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = embed_text(\"Never growing up\")\n",
        "filters = {\"field\": \"genres\", \"operator\": \"in\", \"value\": [\"Comedy\"]}\n",
        "\n",
        "similar_documents = document_store.query_by_embedding(query_embedding, top_k=10, filters=filters)\n",
        "\n",
        "display(similar_documents)"
      ],
      "metadata": {
        "id": "AqdxfsXhbac8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore RAG Pipelines"
      ],
      "metadata": {
        "id": "iFkKGaB6qGqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers # required for producing embeddings in our examples\n",
        "!pip install neo4j-haystack"
      ],
      "metadata": {
        "id": "XMfaBYkai4HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup common utils and constants\n",
        "from google.colab import userdata\n",
        "\n",
        "GRAPH_DB_URI = userdata.get(\"GRAPH_DB_URI\")\n",
        "GRAPH_DB_NAME = userdata.get(\"GRAPH_DB_NAME\")\n",
        "GRAPH_DB_SECRET = userdata.get(\"GRAPH_DB_SECRET\")\n",
        "\n",
        "GOT_DOCS_DIR=\"data/got\"\n",
        "GOT_ZIP_URL=\"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt6.zip\"\n",
        "\n",
        "MODEL_EMBEDDING_DIM=384\n",
        "MODEL_EMBEDDING_NAME=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "HF_API_TOKEN=userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "OG_6GS8zsMsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download Game of Thrones (GOT) wiki\n",
        "!mkdir -p $GOT_DOCS_DIR\n",
        "!wget $GOT_ZIP_URL -O wiki_gameofthrones_txt6.zip\n",
        "!unzip -o wiki_gameofthrones_txt6.zip -d $GOT_DOCS_DIR"
      ],
      "metadata": {
        "id": "KnNgsasOvZ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing Pipeline"
      ],
      "metadata": {
        "id": "o9yZJVEjrOfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pipeline will:\n",
        "\n",
        "* Convert wiki txt files to Document using [TextFileToDocument](https://docs.haystack.deepset.ai/docs/textfiletodocument) component\n",
        "* Preprocess documents with [DocumentCleaner](https://docs.haystack.deepset.ai/docs/documentcleaner), e.g. remove empty lines\n",
        "* Split Documents by chunks of length 250 using [DocumentSplitter](https://docs.haystack.deepset.ai/docs/documentsplitter)\n",
        "* Embed resulting chunked Documents with SentenceTransformersDocumentEmbedder\n",
        "* Write Document chunks to Neo4j as Graph Nodes using [DocumentWriter](https://docs.haystack.deepset.ai/docs/documentwriter)\n",
        "\n",
        "> **Note** How `DocumentWriter` is given `Neo4jDocumentStore` as a store to rite documents to. Here comes the benefit of haaving a common Protocol for multiple stores.\n",
        "\n"
      ],
      "metadata": {
        "id": "50Gh_Qimx135"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from haystack import Pipeline\n",
        "from haystack.components.converters import TextFileToDocument\n",
        "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.writers import DocumentWriter\n",
        "\n",
        "from neo4j_haystack import Neo4jDocumentStore\n",
        "\n",
        "document_store = Neo4jDocumentStore(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        "    embedding_dim=MODEL_EMBEDDING_DIM,\n",
        "    create_index_if_missing=True,\n",
        ")\n",
        "\n",
        "# Create components and an indexing pipeline that converts txt to documents, cleans and splits them, and\n",
        "# indexes them for dense retrieval.\n",
        "pipe = Pipeline()\n",
        "pipe.add_component(\"text_file_converter\", TextFileToDocument())\n",
        "pipe.add_component(\"cleaner\", DocumentCleaner())\n",
        "pipe.add_component(\"splitter\", DocumentSplitter(split_by=\"word\", split_length=400, split_overlap=30))\n",
        "pipe.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model=MODEL_EMBEDDING_NAME))\n",
        "pipe.add_component(\"writer\", DocumentWriter(document_store=document_store))\n",
        "\n",
        "pipe.connect(\"text_file_converter.documents\", \"cleaner.documents\")\n",
        "pipe.connect(\"cleaner.documents\", \"splitter.documents\")\n",
        "pipe.connect(\"splitter.documents\", \"embedder.documents\")\n",
        "pipe.connect(\"embedder.documents\", \"writer.documents\")\n",
        "\n",
        "doc_sources=[GOT_DOCS_DIR / Path(name) for name in os.listdir(GOT_DOCS_DIR)]\n",
        "result = pipe.run({\"text_file_converter\": {\"sources\": doc_sources}})\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "id": "_QKpduk3rSsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display pipeliine diagram\n",
        "pipe.show()"
      ],
      "metadata": {
        "id": "IbBiJlSMt41i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count number oof documents written\n",
        "document_store.count_documents()"
      ],
      "metadata": {
        "id": "t8b-B6QvzhDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generative Question Answering Pipeline"
      ],
      "metadata": {
        "id": "otckaudo2JyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pipeline will:\n",
        "\n",
        "* Create `Neo4jDocumentStore` with required credentials. It will be used to connect to previously indexed documents\n",
        "* Embed text query (our question) using [SentenceTransformersTextEmbedder](https://docs.haystack.deepset.ai/docs/sentencetransformerstextembedder)\n",
        "* Pass query embedding to [Neo4jEmbeddingRetriever](https://prosto.github.io/neo4j-haystack/reference/neo4j_retriever/#neo4j_haystack.components.neo4j_retriever.Neo4jEmbeddingRetriever) which will obtain similar documents from `Neo4jDocumentStore`\n",
        "* Construct simple Q/A prompt using [PromptBuilder](https://docs.haystack.deepset.ai/docs/promptbuilder) by passing over retrieved documents from Neo4j as a prompt context\n",
        "* Ask \"Mistral-7B\" model the question with context consisting of previously found doccuments. [HuggingFaceTGIGenerator](https://docs.haystack.deepset.ai/docs/huggingfacetgigenerator) will interact with TGI endpoint and require HF_TOKEN for this.\n",
        "* Generated answer is parsed/composed by the [AnswerBuilder](https://docs.haystack.deepset.ai/docs/answerbuilder) component as a final execution step of the pipeline"
      ],
      "metadata": {
        "id": "bVR0l8qC-72q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import GeneratedAnswer, Pipeline\n",
        "from haystack.components.builders.answer_builder import AnswerBuilder\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.utils import Secret\n",
        "\n",
        "from neo4j_haystack import Neo4jDocumentStore, Neo4jEmbeddingRetriever\n",
        "\n",
        "HF_TOKEN = Secret.from_token(HF_API_TOKEN)\n",
        "\n",
        "document_store = Neo4jDocumentStore(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        "    embedding_dim=MODEL_EMBEDDING_DIM,\n",
        "    create_index_if_missing=False,\n",
        ")\n",
        "\n",
        "# Build a RAG pipeline with a Retriever to get relevant documents to the query and a HuggingFaceTGIGenerator\n",
        "# interacting with LLMs using a custom prompt.\n",
        "prompt_template = \"\"\"\n",
        "Given these documents, answer the question.\\nDocuments:\n",
        "{% for doc in documents %}\n",
        "    {{ doc.content }}\n",
        "{% endfor %}\n",
        "\n",
        "\\nQuestion: {{question}}\n",
        "\\nAnswer:\n",
        "\"\"\"\n",
        "pipe = Pipeline()\n",
        "pipe.add_component(\n",
        "    \"query_embedder\",\n",
        "    SentenceTransformersTextEmbedder(model=MODEL_EMBEDDING_NAME, progress_bar=False),\n",
        ")\n",
        "pipe.add_component(\"retriever\", Neo4jEmbeddingRetriever(document_store=document_store))\n",
        "pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
        "pipe.add_component(\n",
        "    \"llm\",\n",
        "    HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-v0.1\", token=HF_TOKEN),\n",
        ")\n",
        "pipe.add_component(\"answer_builder\", AnswerBuilder())\n",
        "\n",
        "pipe.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
        "pipe.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
        "pipe.connect(\"llm.replies\", \"answer_builder.replies\")\n",
        "pipe.connect(\"llm.meta\", \"answer_builder.meta\")\n",
        "pipe.connect(\"retriever\", \"answer_builder.documents\")\n",
        "\n",
        "# Ask a question on the data you just added.\n",
        "question = \"Who created the Dothraki vocabulary?\"\n",
        "result = pipe.run(\n",
        "    {\n",
        "        \"query_embedder\": {\"text\": question},\n",
        "        \"retriever\": {\"top_k\": 3},\n",
        "        \"prompt_builder\": {\"question\": question},\n",
        "        \"answer_builder\": {\"query\": question},\n",
        "    }\n",
        ")\n",
        "\n",
        "# For details, like which documents were used to generate the answer, look into the GeneratedAnswer object\n",
        "answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n",
        "\n",
        "display(f\"\"\"\n",
        "Query: {answer.query}\n",
        "Answer: ${answer.data}\n",
        "== Sources: {'\\n'.join([doc.meta['file_path'] for doc in answer.documents])}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "0OCBB5ig2kB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG on Existing Graph"
      ],
      "metadata": {
        "id": "5tN4h5EiWxV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prerequistes*\n",
        "\n",
        "*To test the pipeline you need a \"Movie Graph\" database with data and embeddings. We can [import an existing database](https://neo4j.com/docs/aura/auradb/importing/import-database/) from [github repo](https://github.com/prosto/neo4j-haystack-playground/blob/main/data/movie-graph-with-embeddings-384.dump).*\n",
        "\n",
        "*`movie-graph-with-embeddings-384.dump` comes with embeddings for the `Movie:tagline` text field and `movie-embeddings` vector index. The `sentence-transformers/all-MiniLM-L6-v2` model was used to generate embeddings with dimension `384`*\n",
        "\n",
        "*Before importing you might need to [clean up](https://neo4j.com/docs/aura/auradb/managing-databases/database-actions/#_resetting_an_instance) AuraDB Free instance to have a pristine setup for the next exercise.*"
      ],
      "metadata": {
        "id": "kEMKi8cqapMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In certain scenarios you might have an existing graph in Neo4j database which was created by custom scripts or data ingestion pipelines. The schema of the graph could be complex and not exactly fitting into Haystack Document model. Moreover in many situations you might want to leverage existing graph data to extract more context for grounding LLMs. To make it possible with Haystack `neo4j-haaystack` package provides [Neo4jDynamicDocumentRetriever](https://prosto.github.io/neo4j-haystack/reference/neo4j_retriever/#neo4j_haystack.components.neo4j_retriever.Neo4jDynamicDocumentRetriever) component - a flexible retriever which can run arbitrary Cypher query to obtain documents. This component does not require Document Store to operate.\n",
        "\n",
        "We will use the \"Movie Graph\" we created before to find best matching tagline for a movie.\n",
        "\n",
        "Below is the schema of the Movie Graph to help us understand how to query Neo4j:\n",
        "\n",
        "<table width=\"100%\"><tr>\n",
        "<td bgcolor=\"5b6663\" align=\"center\" valign=\"center\">\n",
        "<img width=\"23%\" src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/2e41a0f8b247eed21d69a28e9ebcd1261c854c6d/images/movie-graph-schema.svg\"/>\n",
        "</td>\n",
        "</tr></table>\n",
        "\n",
        "To better understand what data is available in each Graph node lets look at the table below:\n",
        "\n",
        "```\n",
        "‚ïí‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
        "‚îÇnodeType   ‚îÇnodeLabels‚îÇpropertyName‚îÇpropertyTypes ‚îÇmandatory‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ\":`Person`\"‚îÇ[\"Person\"]‚îÇ\"born\"      ‚îÇ[\"Long\"]      ‚îÇfalse    ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Person`\"‚îÇ[\"Person\"]‚îÇ\"name\"      ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Movie`\" ‚îÇ[\"Movie\"] ‚îÇ\"tagline\"   ‚îÇ[\"String\"]    ‚îÇfalse    ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Movie`\" ‚îÇ[\"Movie\"] ‚îÇ\"title\"     ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Movie`\" ‚îÇ[\"Movie\"] ‚îÇ\"released\"  ‚îÇ[\"Long\"]      ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Movie`\" ‚îÇ[\"Movie\"] ‚îÇ\"embedding\" ‚îÇ[\"FloatArray\"]‚îÇtrue     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "> **Note** In our case `embedding` field stores the embedding vector for the `tagline` field\n",
        "\n",
        "Our pipeline will:\n",
        "\n",
        "* Create `Neo4jDynamicDocumentRetriever` with required credentials and Cypher query to find matching taglines and respective movies. We will also collect related actors and directors for found movies. We could use all this information if the LLM prompt\n",
        "* Embed tagline guess using `SentenceTransformersTextEmbedder`. Idea is to search for something that comes to our mind and \"resonates\" with some movie.\n",
        "* Pass query embedding to `Neo4jDynamicDocumentRetriever` which will obtain movies with additional data directly from Neo4j (we do not use `Neo4jDocumentStore` here)\n",
        "* Construct prompt `PromptBuilder` instructing LLM to pick up best matching tagline and compose letter to the movie diretor explaining the tagline.\n",
        "* Ask \"Mixtral-8x7B-Instruct-v0.1\" LLM model to generate email letter based on the prompt from the builder.\n",
        "* Compose answer data with `AnswerBuilder` component and display results with respective movies found in Neo4j\n"
      ],
      "metadata": {
        "id": "b5TdkYnoXrEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import GeneratedAnswer, Pipeline\n",
        "from haystack.components.builders.answer_builder import AnswerBuilder\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.utils import Secret\n",
        "\n",
        "from neo4j_haystack import Neo4jClientConfig, Neo4jDynamicDocumentRetriever\n",
        "\n",
        "HF_TOKEN = Secret.from_token(HF_API_TOKEN)\n",
        "\n",
        "client_config = Neo4jClientConfig(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        ")\n",
        "\n",
        "rag_cypher_query = \"\"\"\n",
        "  CALL db.index.vector.queryNodes($index, $top_k, $query_embedding)\n",
        "  YIELD node as movie, score\n",
        "  MATCH (movie)\n",
        "  WITH movie, score\n",
        "  MATCH (actor:Person)-[:ACTED_IN]->(movie), (director:Person)-[:DIRECTED]->(movie)\n",
        "  WITH movie, score, COLLECT(distinct actor.name) AS actors, COLLECT(distinct director.name) AS directors\n",
        "  RETURN movie{.*, content: movie.tagline, score, actors, directors}\n",
        "  ORDER BY score DESC LIMIT $top_k\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Given the list of Movies with it's title, tagline and movie directors pick up\n",
        "one of the taglines which matches the given guess and write a short email letter to the movie\n",
        "director of the matched tagline explaining the meaning of the tagline.\n",
        "The letter should be concise and have no more than 3 setntences.\n",
        "Sign the letter with the name: \"{{letter_from}}\".\n",
        "\n",
        "\\nMovies:\n",
        "{% for doc in documents %}\n",
        "  - Title: {{ doc.meta['title'] }}, Tagline: {{ doc.meta['tagline'] }}, Directors: {{ doc.meta['directors'] }}\n",
        "{% endfor %}\n",
        "\n",
        "\\nTagline Guess: {{tagline_guess}}\n",
        "\\nLetter to the director:\n",
        "\"\"\"\n",
        "pipe = Pipeline()\n",
        "pipe.add_component(\n",
        "    \"query_embedder\",\n",
        "    SentenceTransformersTextEmbedder(model=MODEL_EMBEDDING_NAME, progress_bar=False),\n",
        ")\n",
        "pipe.add_component(\n",
        "    \"retriever\",\n",
        "    Neo4jDynamicDocumentRetriever(\n",
        "        client_config=client_config,\n",
        "        runtime_parameters=[\"query_embedding\"],\n",
        "        doc_node_name=\"movie\",\n",
        "        verify_connectivity=True,\n",
        "    ),\n",
        ")\n",
        "pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
        "pipe.add_component(\n",
        "    \"llm\",\n",
        "    HuggingFaceTGIGenerator(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                            token=HF_TOKEN,\n",
        "                            generation_kwargs={ \"max_new_tokens\": 500 }),\n",
        ")\n",
        "pipe.add_component(\"answer_builder\", AnswerBuilder())\n",
        "\n",
        "pipe.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
        "pipe.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
        "pipe.connect(\"llm.replies\", \"answer_builder.replies\")\n",
        "pipe.connect(\"llm.meta\", \"answer_builder.meta\")\n",
        "pipe.connect(\"retriever\", \"answer_builder.documents\")\n",
        "\n",
        "# Ask a question on the data you just added.\n",
        "tagline_guess = \"Have we ever met before?\"\n",
        "result = pipe.run(\n",
        "    {\n",
        "        \"query_embedder\": {\"text\": tagline_guess},\n",
        "        \"retriever\": {\n",
        "            \"query\": rag_cypher_query,\n",
        "            \"parameters\": {\"index\": \"movie-embeddings\", \"top_k\": 5},\n",
        "        },\n",
        "        \"prompt_builder\": {\"tagline_guess\": tagline_guess, \"letter_from\": \"Sergey\"},\n",
        "        \"answer_builder\": {\"query\": tagline_guess},\n",
        "    }\n",
        ")\n",
        "\n",
        "answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n",
        "\n",
        "def movie_sources():\n",
        "  sources = []\n",
        "  for movie_doc in answer.documents:\n",
        "    movie_info = (\n",
        "        f\"Score: {movie_doc.score}, \"\n",
        "        f\"Movie Title: {movie_doc.meta['title']}, \"\n",
        "        f\"Movie Tagline: {movie_doc.meta['tagline']}, \"\n",
        "        f\"Directors: {str(movie_doc.meta['directors'])}\"\n",
        "    )\n",
        "    sources.append(movie_info)\n",
        "  return sources\n",
        "\n",
        "print(answer.data)\n",
        "print(\"============\")\n",
        "print(\"\\n\".join(movie_sources()))"
      ],
      "metadata": {
        "id": "y_yyXrJAYHUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG and Parent Document"
      ],
      "metadata": {
        "id": "GuWnXRiznw0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prerequistes*\n",
        "\n",
        "*To test the pipeline you will need a \"Dune Graph\" database with data and embeddings. [Import an existing database](https://neo4j.com/docs/aura/auradb/importing/import-database/) from [github repo](https://github.com/prosto/neo4j-haystack-playground/blob/main/data/dune-parent-child.dump).*\n",
        "\n",
        "*`dune-parent-child.dump` comes with `Document` and `Chunk` nodes and `chunk-embeddings` vector index. The `sentence-transformers/all-MiniLM-L6-v2` model was used to generate embeddings with dimension `384`*\n",
        "\n",
        "*Before importing you might need to [clean up](https://neo4j.com/docs/aura/auradb/managing-databases/database-actions/#_resetting_an_instance) AuraDB Free instance to have a pristine setup for the next exercise.*"
      ],
      "metadata": {
        "id": "Rng9hZ1zwWZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have options to enhance your RAG pipeline with data having various schemas, for example by first finding nodes using vector search and then expanding query to search for nearby nodes using appropriate Cypher syntax. It is possible to implement \"Parent-Child\" chunking strategy with such approach. Before that you have to ingest/index data into Neo4j accordingly by building an indexing pipeline or a custom ingestion script. A simple schema is shown below:\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Chunk    ‚îÇ                ‚îÇ   Document  ‚îÇ\n",
        "‚îÇ            ‚îÇ  :HAS_PARENT   ‚îÇ             ‚îÇ\n",
        "‚îÇ   content  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   content   ‚îÇ\n",
        "‚îÇ  embedding ‚îÇ                ‚îÇ             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```"
      ],
      "metadata": {
        "id": "Vzoj8J2rse2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `dune-parent-child.dump` was created by running a script which chunks the [dune.txt](https://github.com/prosto/neo4j-haystack-playground/blob/main/data/dune.txt) text with following rules:\n",
        "\n",
        "* The whole text is chunked with: `split_by=\"word\", split_length=512, split_overlap=30` settings. `Document` node is created in Neo4j respectively with `content` property\n",
        "* Each `Document` is further split with `split_by=\"word\", split_length=100, split_overlap=24` settings resulting in `Chunk` nodes\n",
        "* `chunk-embeddings` vector index is created based on `content` of `Chunk` nodes using embeddings generated by `sentence-transformers/all-MiniLM-L6-v2` model\n",
        "\n",
        "The image below depicts simple relationship (`:HAS_PARENT`) we have between `Document` (green nodes in center) and `Chunks`\n",
        "\n",
        "<table width=\"100%\"><tr>\n",
        "<td bgcolor=\"5b6663\" align=\"center\" valign=\"center\">\n",
        "<img width=\"50%\" src=\"https://raw.githubusercontent.com/prosto/neo4j-haystack-playground/68aeffa211455278b31bec8c5b81601b431c2a16/images/parent-child-graph.svg\"/>\n",
        "</td>\n",
        "</tr></table>\n",
        "\n",
        "To get the final picture lets see what node properties are storeed in each node:\n",
        "\n",
        "```\n",
        "‚ïí‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
        "‚îÇnodeType     ‚îÇnodeLabels  ‚îÇpropertyName‚îÇpropertyTypes ‚îÇmandatory‚îÇ\n",
        "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
        "‚îÇ\":`Chunk`\"   ‚îÇ[\"Chunk\"]   ‚îÇ\"id\"        ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Chunk`\"   ‚îÇ[\"Chunk\"]   ‚îÇ\"file_path\" ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Chunk`\"   ‚îÇ[\"Chunk\"]   ‚îÇ\"source_id\" ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Chunk`\"   ‚îÇ[\"Chunk\"]   ‚îÇ\"content\"   ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Chunk`\"   ‚îÇ[\"Chunk\"]   ‚îÇ\"embedding\" ‚îÇ[\"FloatArray\"]‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Document`\"‚îÇ[\"Document\"]‚îÇ\"id\"        ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Document`\"‚îÇ[\"Document\"]‚îÇ\"file_path\" ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Document`\"‚îÇ[\"Document\"]‚îÇ\"source_id\" ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ\":`Document`\"‚îÇ[\"Document\"]‚îÇ\"content\"   ‚îÇ[\"String\"]    ‚îÇtrue     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "> **Note** `Chunk` nodes have a property called `source_id` which is an `id` of its paarent `Document`"
      ],
      "metadata": {
        "id": "9x9wMcGk0SdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pipeline will:\n",
        "\n",
        "* Create `Neo4jDynamicDocumentRetriever` with required credentials and Cypher query to find Chunks and then respective prent Documents. The maximum score is calculated from the list of Chunks which belong to the saame Document\n",
        "* Embed question using `SentenceTransformersTextEmbedder`. Idea is to search for parent Documents which provide iser context for LLM to nswer the question\n",
        "* Pass query embedding to `Neo4jDynamicDocumentRetriever` which will obtain parent documents\n",
        "* Construct prompt `PromptBuilder` instructing LLM to answer the question based on parent Documents\n",
        "* Ask \"Mixtral-8x7B-Instruct-v0.1\" LLM model to generate the answer\n",
        "* Compose answer data with `AnswerBuilder` component and display the answer\n",
        "\n",
        "> **Important** Please pay attention to the `cypher_query` as it contains the Cypher query responsible for finding parent Documents and thus does all the work. Rest of pipeline is typical RAG"
      ],
      "metadata": {
        "id": "FNv8VYlv3wh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import GeneratedAnswer, Pipeline\n",
        "from haystack.components.builders.answer_builder import AnswerBuilder\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.utils.auth import Secret\n",
        "\n",
        "from neo4j_haystack import Neo4jClientConfig, Neo4jDynamicDocumentRetriever\n",
        "\n",
        "HF_TOKEN = Secret.from_token(HF_API_TOKEN)\n",
        "\n",
        "client_config = Neo4jClientConfig(\n",
        "    url=GRAPH_DB_URI,\n",
        "    username=\"neo4j\",\n",
        "    password=GRAPH_DB_SECRET,\n",
        "    database=GRAPH_DB_NAME,\n",
        ")\n",
        "\n",
        "cypher_query = \"\"\"\n",
        "            // Query Child documents by $query_embedding\n",
        "            CALL db.index.vector.queryNodes($index, $top_k, $query_embedding)\n",
        "            YIELD node as child_doc, score\n",
        "\n",
        "            // Find Parent document for previously retrieved child (e.g. extend RAG context)\n",
        "            MATCH (child_doc)-[:HAS_PARENT]->(parent:Document)\n",
        "            WITH parent, max(score) AS score // deduplicate parents\n",
        "            RETURN parent{.*, score}\n",
        "        \"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Given these documents, answer the question.\\nDocuments:\n",
        "{% for doc in documents %}\n",
        "    {{ doc.content }}\n",
        "{% endfor %}\n",
        "\n",
        "\\nQuestion: {{question}}\n",
        "\\nAnswer:\n",
        "\"\"\"\n",
        "rag_pipeline = Pipeline()\n",
        "rag_pipeline.add_component(\n",
        "    \"query_embedder\",\n",
        "    SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\", progress_bar=False),\n",
        ")\n",
        "rag_pipeline.add_component(\n",
        "    \"retriever\",\n",
        "    Neo4jDynamicDocumentRetriever(\n",
        "        client_config=client_config,\n",
        "        runtime_parameters=[\"query_embedding\"],\n",
        "        doc_node_name=\"parent\",\n",
        "        verify_connectivity=True,\n",
        "    ),\n",
        ")\n",
        "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\n",
        "rag_pipeline.add_component(\n",
        "    \"llm\",\n",
        "    HuggingFaceTGIGenerator(\n",
        "        model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "        token=HF_TOKEN,\n",
        "        generation_kwargs={\"max_new_tokens\": 120, \"stop_sequences\": [\".\"]},\n",
        "    ),\n",
        ")\n",
        "rag_pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
        "\n",
        "rag_pipeline.connect(\"query_embedder\", \"retriever.query_embedding\")\n",
        "rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
        "rag_pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
        "rag_pipeline.connect(\"llm.meta\", \"answer_builder.meta\")\n",
        "rag_pipeline.connect(\"retriever\", \"answer_builder.documents\")\n",
        "\n",
        "question = \"Why did author suppressed technology in the Dune universe?\"\n",
        "result = rag_pipeline.run(\n",
        "    {\n",
        "        \"query_embedder\": {\"text\": question},\n",
        "        \"retriever\": {\n",
        "            \"query\": cypher_query,\n",
        "            \"parameters\": {\"index\": \"chunk-embeddings\", \"top_k\": 5},\n",
        "        },\n",
        "        \"prompt_builder\": {\"question\": question},\n",
        "        \"answer_builder\": {\"query\": question},\n",
        "    }\n",
        ")\n",
        "\n",
        "answer: GeneratedAnswer = result[\"answer_builder\"][\"answers\"][0]\n",
        "\n",
        "print(\"Query: \", answer.query)\n",
        "print(\"Answer: \", answer.data)\n",
        "print(\"== Sources:\")\n",
        "for doc in answer.documents:\n",
        "    print(\"-> \", doc)\n"
      ],
      "metadata": {
        "id": "d5Q__kLuolyW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o9yZJVEjrOfu",
        "otckaudo2JyC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}